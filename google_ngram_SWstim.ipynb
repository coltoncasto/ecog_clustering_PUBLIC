{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c550ffc2-701b-4edc-81a8-160da0699063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import csv\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07ed17b-30e5-4bf8-b3b8-245557f3c8e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def runQuery(query, start_year=1850,\n",
    "\t\t\tend_year=1860, corpus=26,\n",
    "\t\t\tsmoothing=0):\n",
    "\n",
    "    # converting a regular string to\n",
    "    # the standard URL format\n",
    "    # eg: \"geeks for,geeks\" will\n",
    "    # convert to \"geeks%20for%2Cgeeks\"\n",
    "    query = urllib.parse.quote(query)\n",
    "    # print(query)\n",
    "    # creating the URL\n",
    "    url = 'https://books.google.com/ngrams/json?content=' + query +'&year_start=' + str(start_year) + '&year_end=' +str(end_year) + '&corpus=' + str(corpus) + '&smoothing=' +str(smoothing) + ''\n",
    "    #print(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # requesting data from the above url\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    #print(response.status_code)\n",
    "    #if response.status_code != 200:\n",
    "    #    return(query)\n",
    "    #     for i in range(10):\n",
    "    #         response = requests.get(url)\n",
    "    #         if response.status_code == 200:\n",
    "    #             continue\n",
    "    # extracting the json data from the response we got\n",
    "    # print(response.status_code)\n",
    "    # print(type(response))\n",
    "    \n",
    "    output = response.json()\n",
    "    \n",
    "    # creating a list to store the ngram data\n",
    "    return_data = []\n",
    "    \n",
    "    if len(output) == 0:\n",
    "        # if no data returned from site,\n",
    "        # print the following statement\n",
    "        return \"No data available for this Ngram.\"\n",
    "    else:\n",
    "        # if data returned from site,\n",
    "        # store the data in return_data list\n",
    "        for num in range(len(output)):\n",
    "            \n",
    "            # getting the name\n",
    "            return_data.append((output[num]['ngram'],\n",
    "                                \n",
    "                                # getting ngram data\n",
    "                                output[num]['timeseries'])\n",
    "                            )\n",
    "    \n",
    "    return return_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6141cf45-d37c-4c79-a709-47b2d89edc58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#query = \"Albert Einstein\"\n",
    "#print(runQuery(query))\n",
    "#print(runQuery(query,start_year=1900, end_year=2000))\n",
    "#my_queries = list()\n",
    "#my_queries = [\"brain\", \"cognitive\"]\n",
    "#my_result = {}\n",
    "#for query in my_queries:\n",
    "#    my_result[query] = runQuery(query,start_year=1900, end_year=2000)\n",
    "# my_result[\"brain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce94a0c-87a8-4091-8fff-1d740b57c88a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def txtfile_to_list(path):\n",
    "    #read a stimulus text file into a list\n",
    "    \n",
    "    lines_as_lists = []\n",
    "    \n",
    "    # Open the text file for reading\n",
    "    with open(path, 'r') as file:\n",
    "        # Loop through each line in the file\n",
    "        for line in file:\n",
    "            # Split the line into words using commas as the delimiter\n",
    "            words = line.strip().split(',')\n",
    "            \n",
    "            # Join the words with spaces instead of commas\n",
    "            line_without_commas = ' '.join(words)\n",
    "            \n",
    "            # Append the modified line to the list\n",
    "            lines_as_lists.append(line_without_commas)\n",
    "    \n",
    "    # Now, 'lines_as_lists' contains each line from the file as a list of words with spaces instead of commas\n",
    "    return lines_as_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d6e6a55-6270-4177-bdbf-836ae17c336e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_ngrams_from_list(list, startyear, endyear):\n",
    "    my_result = []\n",
    "    ii = 0\n",
    "    for query in tqdm.tqdm(list[ii:]):\n",
    "        result = runQuery(query,startyear, endyear)\n",
    "        my_result.append(result)   \n",
    "        ii= ii+1\n",
    "    return my_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e06efe06-441b-430a-aa29-4026328b1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV_from_result(csv_file_path, entries, my_results, startyear, endyear):\n",
    "    # Create a list to store the data rows for the CSV\n",
    "    data_rows = []\n",
    "\n",
    "    # Iterate over entries and my_results in parallel\n",
    "    for entry, result in zip(entries, my_results):\n",
    "        # Create a dictionary to represent each row\n",
    "        row_data = {'Entry': entry}\n",
    "\n",
    "        # Handle the case where there is no data available\n",
    "        if isinstance(result, str) and result == 'No data available for this Ngram':\n",
    "            row_data['Text'] = result\n",
    "            # Initialize data columns with None\n",
    "            for year in range(startyear, endyear):\n",
    "                row_data[str(year)] = None\n",
    "        elif isinstance(result, list) and len(result) == 1 and isinstance(result[0], tuple) and len(result[0]) == 2:\n",
    "            text, values = result[0]\n",
    "            row_data['Text'] = text\n",
    "            # Initialize data columns with values or None if not enough values are provided\n",
    "            for year, value in zip(range(startyear, endyear), values):\n",
    "                row_data[str(year)] = value if year - startyear < len(values) else None\n",
    "        else:\n",
    "            # For invalid entries, store 'No data available for this Ngram' in Text and None in data columns\n",
    "            row_data['Text'] = 'No data available for this Ngram'\n",
    "            for year in range(startyear, endyear):\n",
    "                row_data[str(year)] = None\n",
    "\n",
    "        # Append the row data to the list of data rows\n",
    "        data_rows.append(row_data)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Entry', 'Text'] + [str(year) for year in range(startyear, endyear)]\n",
    "        csvwriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header row\n",
    "        csvwriter.writeheader()\n",
    "\n",
    "        # Write the data rows\n",
    "        csvwriter.writerows(data_rows)\n",
    "\n",
    "    print(f'CSV file has been saved to {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f6981a2-16a8-4bbf-939f-4466f5dcc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_dir = 'stimuli/ngram/';\n",
    "ngram_ns = [number for number in range(1, 5)]\n",
    "startyear = 2010\n",
    "endyear = 2020\n",
    "nyears = endyear - startyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "301a0902-2028-4e41-9c7c-ebe521e16854",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT ngram #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 640/640 [12:56<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved to stimuli/ngram/frequency_sentences_ngram_n1.csv\n",
      "WORD ngram #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 640/640 [13:09<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved to stimuli/ngram/frequency_words_ngram_n1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,2):\n",
    "    # run for sentences:\n",
    "    print('SENT ngram #' + str(n))\n",
    "    sentences_stim_path = ngram_dir + 'stimulus_sentences_ngram_n' + str(n) + '.csv';\n",
    "    result_csv_file_path = ngram_dir + 'frequency_sentences_ngram_n' + str(n) + '.csv';\n",
    "    lines_as_list = txtfile_to_list(sentences_stim_path)\n",
    "    my_result = calc_ngrams_from_list(lines_as_list[1:], startyear, endyear)\n",
    "    writeCSV_from_result(result_csv_file_path, lines_as_list[1:], my_result, startyear, endyear)\n",
    "\n",
    "    # run for word lists:\n",
    "    print('WORD ngram #' + str(n))\n",
    "    words_stim_path = ngram_dir + 'stimulus_words_ngram_n' + str(n) + '.csv';\n",
    "    result_csv_file_path = ngram_dir + 'frequency_words_ngram_n' + str(n) + '.csv';\n",
    "    lines_as_list = txtfile_to_list(words_stim_path)\n",
    "    my_result = calc_ngrams_from_list(lines_as_list[1:], startyear, endyear)\n",
    "    writeCSV_from_result(result_csv_file_path, lines_as_list[1:], my_result, startyear, endyear)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c947fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
